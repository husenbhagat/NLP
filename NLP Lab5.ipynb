{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 1: demo for POS Tagged Corpora in nltk:Brown and Penn Treebank\n",
    "# the Brown corpus has its own set of POS tags\n",
    "\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'AT'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('County', 'NN-TL'),\n",
       "  ('Grand', 'JJ-TL'),\n",
       "  ('Jury', 'NN-TL'),\n",
       "  ('said', 'VBD'),\n",
       "  ('Friday', 'NR'),\n",
       "  ('an', 'AT'),\n",
       "  ('investigation', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  (\"Atlanta's\", 'NP$'),\n",
       "  ('recent', 'JJ'),\n",
       "  ('primary', 'NN'),\n",
       "  ('election', 'NN'),\n",
       "  ('produced', 'VBD'),\n",
       "  ('``', '``'),\n",
       "  ('no', 'AT'),\n",
       "  ('evidence', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('that', 'CS'),\n",
       "  ('any', 'DTI'),\n",
       "  ('irregularities', 'NNS'),\n",
       "  ('took', 'VBD'),\n",
       "  ('place', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('further', 'RBR'),\n",
       "  ('said', 'VBD'),\n",
       "  ('in', 'IN'),\n",
       "  ('term-end', 'NN'),\n",
       "  ('presentments', 'NNS'),\n",
       "  ('that', 'CS'),\n",
       "  ('the', 'AT'),\n",
       "  ('City', 'NN-TL'),\n",
       "  ('Executive', 'JJ-TL'),\n",
       "  ('Committee', 'NN-TL'),\n",
       "  (',', ','),\n",
       "  ('which', 'WDT'),\n",
       "  ('had', 'HVD'),\n",
       "  ('over-all', 'JJ'),\n",
       "  ('charge', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('election', 'NN'),\n",
       "  (',', ','),\n",
       "  ('``', '``'),\n",
       "  ('deserves', 'VBZ'),\n",
       "  ('the', 'AT'),\n",
       "  ('praise', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('thanks', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('City', 'NN-TL'),\n",
       "  ('of', 'IN-TL'),\n",
       "  ('Atlanta', 'NP-TL'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('for', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('manner', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('which', 'WDT'),\n",
       "  ('the', 'AT'),\n",
       "  ('election', 'NN'),\n",
       "  ('was', 'BEDZ'),\n",
       "  ('conducted', 'VBN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the tagged_sents function gives POS tagged sentences and tagged_words gives POS tagged words\n",
    "brown.tagged_sents()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('Grand', 'JJ-TL'),\n",
       " ('Jury', 'NN-TL'),\n",
       " ('said', 'VBD'),\n",
       " ('Friday', 'NR'),\n",
       " ('an', 'AT'),\n",
       " ('investigation', 'NN'),\n",
       " ('of', 'IN'),\n",
       " (\"Atlanta's\", 'NP$'),\n",
       " ('recent', 'JJ'),\n",
       " ('primary', 'NN'),\n",
       " ('election', 'NN'),\n",
       " ('produced', 'VBD'),\n",
       " ('``', '``'),\n",
       " ('no', 'AT'),\n",
       " ('evidence', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('that', 'CS'),\n",
       " ('any', 'DTI'),\n",
       " ('irregularities', 'NNS'),\n",
       " ('took', 'VBD'),\n",
       " ('place', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'AT'),\n",
       " ('jury', 'NN'),\n",
       " ('further', 'RBR'),\n",
       " ('said', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('term-end', 'NN'),\n",
       " ('presentments', 'NNS'),\n",
       " ('that', 'CS'),\n",
       " ('the', 'AT'),\n",
       " ('City', 'NN-TL'),\n",
       " ('Executive', 'JJ-TL'),\n",
       " ('Committee', 'NN-TL'),\n",
       " (',', ','),\n",
       " ('which', 'WDT'),\n",
       " ('had', 'HVD'),\n",
       " ('over-all', 'JJ'),\n",
       " ('charge', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('election', 'NN'),\n",
       " (',', ','),\n",
       " ('``', '``'),\n",
       " ('deserves', 'VBZ'),\n",
       " ('the', 'AT'),\n",
       " ('praise', 'NN')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.tagged_words()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each tagged word is a pair, which Python calls a tuple  \n",
    "#  it behaves like a list except that you can't change the elements (immutable)\n",
    "wordtag = brown.tagged_words()[0]\n",
    "wordtag\n",
    "type(wordtag)\n",
    "wordtag[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AT'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordtag[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the brown corpus can also be accessed by category\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRON'),\n",
       " ('was', 'VERB'),\n",
       " ('among', 'ADP'),\n",
       " ('these', 'DET'),\n",
       " ('that', 'ADP'),\n",
       " ('Hinkle', 'NOUN'),\n",
       " ('identified', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('photograph', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Barco', 'NOUN'),\n",
       " ('!', '.'),\n",
       " ('!', '.'),\n",
       " ('For', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('seems', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('Barco', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('fancying', 'VERB'),\n",
       " ('himself', 'PRON'),\n",
       " ('a', 'DET'),\n",
       " (\"ladies'\", 'NOUN'),\n",
       " ('man', 'NOUN'),\n",
       " ('(', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('why', 'ADV'),\n",
       " ('not', 'ADV'),\n",
       " (',', '.'),\n",
       " ('after', 'ADP'),\n",
       " ('seven', 'NUM'),\n",
       " ('marriages', 'NOUN'),\n",
       " ('?', '.'),\n",
       " ('?', '.'),\n",
       " (')', '.'),\n",
       " (',', '.'),\n",
       " ('had', 'VERB'),\n",
       " ('listed', 'VERB'),\n",
       " ('himself', 'PRON'),\n",
       " ('for', 'ADP'),\n",
       " ('Mormon', 'NOUN'),\n",
       " ('Beard', 'NOUN'),\n",
       " ('roles', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('instigation', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('his', 'DET'),\n",
       " ('fourth', 'ADJ'),\n",
       " ('murder', 'NOUN')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_humor_tagged = brown.tagged_words(categories='humor', tagset='universal')\n",
    "brown_humor_tagged[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('now', 'RB'),\n",
       " ('im', 'PRP'),\n",
       " ('left', 'VBD'),\n",
       " ('with', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('gay', 'JJ'),\n",
       " ('name', 'NN'),\n",
       " (':P', 'UH'),\n",
       " ('PART', 'VB'),\n",
       " ('hey', 'UH'),\n",
       " ('everyone', 'NN'),\n",
       " ('ah', 'UH'),\n",
       " ('well', 'UH'),\n",
       " ('NICK', 'NN'),\n",
       " (':', ':'),\n",
       " ('U7', 'NNP'),\n",
       " ('U7', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('gay', 'JJ'),\n",
       " ('name', 'NN'),\n",
       " ('.', '.'),\n",
       " ('.', 'SYM'),\n",
       " ('ACTION', 'NN'),\n",
       " ('gives', 'VBZ'),\n",
       " ('U121', 'NNP'),\n",
       " ('a', 'DT'),\n",
       " ('golf', 'NN'),\n",
       " ('clap', 'NN'),\n",
       " ('.', '.'),\n",
       " (':)', 'UH'),\n",
       " ('JOIN', 'VB'),\n",
       " ('hi', 'UH'),\n",
       " ('U59', 'NNP'),\n",
       " ('26', 'CD'),\n",
       " ('/', 'CC'),\n",
       " ('m', 'NN'),\n",
       " ('/', 'CC'),\n",
       " ('ky', 'NNP'),\n",
       " ('women', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('are', 'VBP'),\n",
       " ('nice', 'JJ'),\n",
       " ('please', 'VB'),\n",
       " ('pm', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('JOIN', 'VB'),\n",
       " ('PART', 'VB'),\n",
       " ('there', 'RB'),\n",
       " ('ya', 'PRP')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the chat corpus uses Penn POS tags\n",
    "nltk.corpus.nps_chat.tagged_words()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penn treebank\n",
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( (S \n",
      "    (NP-SBJ \n",
      "      (NP (NNP Pierre) (NNP Vinken) )\n",
      "      (, ,) \n",
      "      (ADJP \n",
      "        (NP (CD 61) (NNS years) )\n",
      "        (JJ old) )\n",
      "      (, ,) ) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use corpus methods to get the text as strings and as tokens as before\n",
    "treebank_text = treebank.raw()\n",
    "print(treebank_text[:150], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.',\n",
       " 'Mr.',\n",
       " 'Vinken']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank_tokens = treebank.words()\n",
    "treebank_tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.'), ('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.'), ('Rudolph', 'NNP'), ('Agnew', 'NNP'), (',', ','), ('55', 'CD'), ('years', 'NNS'), ('old', 'JJ'), ('and', 'CC'), ('former', 'JJ'), ('chairman', 'NN'), ('of', 'IN'), ('Consolidated', 'NNP'), ('Gold', 'NNP'), ('Fields', 'NNP'), ('PLC', 'NNP'), (',', ','), ('was', 'VBD'), ('named', 'VBN'), ('*-1', '-NONE-'), ('a', 'DT')]\n"
     ]
    }
   ],
   "source": [
    "# but we also have functions to get words with tags and sentences with tagged words\n",
    "treebank_tagged_words = treebank.tagged_words()\n",
    "print(treebank_tagged_words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "treebank_tagged = treebank.tagged_sents()\n",
    "print(treebank_tagged[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NNP', ',', 'CD', 'NNS', 'JJ', 'MD', 'VB', 'DT', 'NN', 'IN', '.', 'VBZ', 'VBG', 'CC', 'VBD', 'VBN', '-NONE-', 'RB', 'TO', 'PRP', 'RBR', 'WDT', 'VBP', 'RP', 'PRP$', 'JJS', 'POS', '``', 'EX', \"''\", 'WP', ':', 'JJR', 'WRB', '$', 'NNPS', 'WP$', '-LRB-', '-RRB-', 'PDT', 'RBS', 'FW', 'UH', 'SYM', 'LS', '#']) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Frequency distribution of tags in Penn Treebank\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in treebank.tagged_words())\n",
    "print(tag_fd.keys(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN 13166\n",
      "IN 9857\n",
      "NNP 9410\n",
      "DT 8165\n",
      "-NONE- 6592\n",
      "NNS 6047\n",
      "JJ 5834\n",
      ", 4886\n",
      ". 3874\n",
      "CD 3546\n",
      "VBD 3043\n",
      "RB 2822\n",
      "VB 2554\n",
      "CC 2265\n",
      "TO 2179\n",
      "VBN 2134\n",
      "VBZ 2125\n",
      "PRP 1716\n",
      "VBG 1460\n",
      "VBP 1321\n",
      "MD 927\n",
      "POS 824\n",
      "PRP$ 766\n",
      "$ 724\n",
      "`` 712\n",
      "'' 694\n",
      ": 563\n",
      "WDT 445\n",
      "JJR 381\n",
      "NNPS 244\n",
      "WP 241\n",
      "RP 216\n",
      "JJS 182\n",
      "WRB 178\n",
      "RBR 136\n",
      "-RRB- 126\n",
      "-LRB- 120\n",
      "EX 88\n",
      "RBS 35\n",
      "PDT 27\n",
      "# 16\n",
      "WP$ 14\n",
      "LS 13\n",
      "FW 4\n",
      "UH 3\n",
      "SYM 1\n"
     ]
    }
   ],
   "source": [
    "for tag,freq in tag_fd.most_common():\n",
    "    print (tag, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['N', ',', 'C', 'J', 'M', 'V', 'D', 'I', '.', '-', 'R', 'T', 'P', 'W', '`', 'E', \"'\", ':', '$', 'F', 'U', 'S', 'L', '#']) \n",
      "\n",
      "N 28867\n",
      "V 12637\n",
      "I 9857\n",
      "D 8165\n",
      "- 6838\n",
      "J 6397\n",
      "C 5811\n",
      ", 4886\n",
      ". 3874\n",
      "P 3333\n",
      "R 3209\n",
      "T 2179\n",
      "M 927\n",
      "W 878\n",
      "$ 724\n",
      "` 712\n",
      "' 694\n",
      ": 563\n",
      "E 88\n",
      "# 16\n",
      "L 13\n",
      "F 4\n",
      "U 3\n",
      "S 1\n"
     ]
    }
   ],
   "source": [
    "# use the first letter of the POS tag to get classes of tags\n",
    "tag_classes_fd = nltk.FreqDist(tag[0] for (word, tag) in treebank.tagged_words())\n",
    "print(tag_classes_fd.keys(), '\\n')\n",
    "for tag,freq in tag_classes_fd.most_common():\n",
    "    print (tag, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3522"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part 2: POS Tagging\n",
    "\n",
    "# Separating the data into training and test data:90% for training data\n",
    "size = int(len(treebank_tagged) * 0.9)\n",
    "treebank_train = treebank_tagged[:size]\n",
    "treebank_test = treebank_tagged[size:]\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NN'), ('Vinken', 'NN'), (',', 'NN'), ('61', 'NN'), ('years', 'NN'), ('old', 'NN'), (',', 'NN'), ('will', 'NN'), ('join', 'NN'), ('the', 'NN'), ('board', 'NN'), ('as', 'NN'), ('a', 'NN'), ('nonexecutive', 'NN'), ('director', 'NN'), ('Nov.', 'NN'), ('29', 'NN'), ('.', 'NN'), ('Mr.', 'NN'), ('Vinken', 'NN'), ('is', 'NN'), ('chairman', 'NN'), ('of', 'NN'), ('Elsevier', 'NN'), ('N.V.', 'NN'), (',', 'NN'), ('the', 'NN'), ('Dutch', 'NN'), ('publishing', 'NN'), ('group', 'NN'), ('.', 'NN'), ('Rudolph', 'NN'), ('Agnew', 'NN'), (',', 'NN'), ('55', 'NN'), ('years', 'NN'), ('old', 'NN'), ('and', 'NN'), ('former', 'NN'), ('chairman', 'NN'), ('of', 'NN'), ('Consolidated', 'NN'), ('Gold', 'NN'), ('Fields', 'NN'), ('PLC', 'NN'), (',', 'NN'), ('was', 'NN'), ('named', 'NN'), ('*-1', 'NN'), ('a', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Default Tagger assign 'NN' to every word\n",
    "# creates the tagger\n",
    "t0 = nltk.DefaultTagger('NN')\n",
    "# show the effect of the tagger by tagging the first 50 words\n",
    "print(t0.tag(treebank_tokens[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14697201017811704\n"
     ]
    }
   ],
   "source": [
    "# evaluate function applies the tagger t0 to the untagged version of treebank\n",
    "#   and compares with the tagged version\n",
    "print(t0.evaluate(treebank_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 3: n-gram tagger\n",
    "# Unigram tagger learns tag with the highest probability for each word\n",
    "# creates the tagger on the training set\n",
    "t1 = nltk.UnigramTagger(treebank_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.'), ('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'JJ'), ('publishing', 'NN'), ('group', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# show the effect of the tagger by tagging the first 50 words\n",
    "print(t1.tag(treebank_tokens[:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8627989821882952"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluates the tagger on the test set\n",
    "t1.evaluate(treebank_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram Tagging with Backoff to Combine Taggers\n",
    "# create a sequence of taggers with backoff to get a bigram tagger\n",
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(treebank_train, backoff=t0)\n",
    "t2 = nltk.BigramTagger(treebank_train, backoff=t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8905852417302799"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy with BigramTagger: \n",
    "t2.evaluate(treebank_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the bigram tagger on some new text\n",
    "text = \"Three Calgarians have found a rather unusual way of leaving snow and ice behind. They set off this week on foot and by camels on a grueling trek across the burning Arabian desert.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Three Calgarians have found a rather unusual way of leaving snow and ice behind.', 'They set off this week on foot and by camels on a grueling trek across the burning Arabian desert.']\n"
     ]
    }
   ],
   "source": [
    "# But we should separate the text into sentences first\n",
    "textsplit = nltk.sent_tokenize(text)\n",
    "print(textsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Three', 'Calgarians', 'have', 'found', 'a', 'rather', 'unusual', 'way', 'of', 'leaving', 'snow', 'and', 'ice', 'behind', '.'], ['They', 'set', 'off', 'this', 'week', 'on', 'foot', 'and', 'by', 'camels', 'on', 'a', 'grueling', 'trek', 'across', 'the', 'burning', 'Arabian', 'desert', '.']]\n"
     ]
    }
   ],
   "source": [
    "# apply the word tokenizer to each sentence\n",
    "tokentext = [nltk.word_tokenize(sent) for sent in textsplit]\n",
    "print(tokentext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Three', 'CD'), ('Calgarians', 'NN'), ('have', 'VBP'), ('found', 'VBN'), ('a', 'DT'), ('rather', 'RB'), ('unusual', 'JJ'), ('way', 'NN'), ('of', 'IN'), ('leaving', 'VBG'), ('snow', 'NN'), ('and', 'CC'), ('ice', 'NN'), ('behind', 'IN'), ('.', '.')], [('They', 'PRP'), ('set', 'VBN'), ('off', 'RP'), ('this', 'DT'), ('week', 'NN'), ('on', 'IN'), ('foot', 'NN'), ('and', 'CC'), ('by', 'IN'), ('camels', 'NN'), ('on', 'IN'), ('a', 'DT'), ('grueling', 'NN'), ('trek', 'NN'), ('across', 'IN'), ('the', 'DT'), ('burning', 'NN'), ('Arabian', 'NN'), ('desert', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# use the t2 bigram tagger to tag each sentence tokens\n",
    "taggedtext = [t2.tag(tokens) for tokens in tokentext]\n",
    "print(taggedtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Three', 'CD'), ('Calgarians', 'NNPS'), ('have', 'VBP'), ('found', 'VBN'), ('a', 'DT'), ('rather', 'RB'), ('unusual', 'JJ'), ('way', 'NN'), ('of', 'IN'), ('leaving', 'VBG'), ('snow', 'NN'), ('and', 'CC'), ('ice', 'NN'), ('behind', 'NN'), ('.', '.')], [('They', 'PRP'), ('set', 'VBD'), ('off', 'RP'), ('this', 'DT'), ('week', 'NN'), ('on', 'IN'), ('foot', 'NN'), ('and', 'CC'), ('by', 'IN'), ('camels', 'NNS'), ('on', 'IN'), ('a', 'DT'), ('grueling', 'NN'), ('trek', 'NN'), ('across', 'IN'), ('the', 'DT'), ('burning', 'NN'), ('Arabian', 'JJ'), ('desert', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# use the Stanford POS tagger to tag each sentence tokens\n",
    "taggedtextStanford = [nltk.pos_tag(tokens) for tokens in tokentext]\n",
    "print(taggedtextStanford)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
